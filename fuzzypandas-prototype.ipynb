{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prototype FuzzyPandas Functions using U.S. News and IPEDS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, let's read in the school ranking data scraped from usnews.com & do a little pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_us_news(pickle):\n",
    "    df = pd.read_pickle(pickle)   \n",
    "    return pd.concat([us_news, df], axis=0, ignore_index=True)\n",
    "\n",
    "us_news = pd.DataFrame() #initialize empty data frame\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-national-universities.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-national-liberal-arts-colleges.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-midwest.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-north.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-south.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-west.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-midwest.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-north.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-south.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-west.pickle\")\n",
    "\n",
    "us_news[\"city\"] = us_news.location.apply(lambda x: x.split(\", \")[0].upper().strip()) #parse out city, to upper case\n",
    "us_news[\"state\"] = us_news.location.apply(lambda x: x.split(\", \")[1].upper().strip()) #parse out state, to upper case\n",
    "us_news[\"school\"] = us_news.school.apply(lambda x: x.upper().strip()) #school name to upper case\n",
    "\n",
    "us_news.drop(\"location\", axis=1, inplace=True) #drop original location (now that we've split out into city and state)\n",
    "us_news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in IPEDS Data & Preprocess. IPEDS Data can be downloaded for free here:**\n",
    "https://nces.ed.gov/ipeds/datacenter/Default.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipeds=pd.read_csv(\"example_data/ipeds/HD2014.csv\")[[\"UNITID\",\"INSTNM\",\"CITY\",\"STABBR\"]]\n",
    "\n",
    "ipeds.rename(columns={\"UNITID\":\"unitid\",\"INSTNM\":\"school\",\"CITY\":\"city\",\"STABBR\":\"state\"},inplace=True) \n",
    "#rename columns to match U.S. News Data\n",
    "\n",
    "ipeds[\"school\"] = ipeds.school.apply(lambda x: x.upper().strip()) #school to upper case\n",
    "ipeds[\"city\"] = ipeds.city.apply(lambda x: x.upper().strip()) #city to upper case\n",
    "ipeds[\"state\"] = ipeds.state.apply(lambda x: x.upper().strip()) #state to upper case\n",
    "ipeds.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Subset Data to Only NY and CT Schools for Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_us_news = us_news[us_news.state.isin([\"CT\",\"NY\"])].copy()\n",
    "test_ipeds = ipeds[ipeds.state.isin([\"CT\",\"NY\"])].copy()\n",
    "\n",
    "print us_news.shape, test_us_news.shape\n",
    "print ipeds.shape, test_ipeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Key Fuzzy Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode_column(text):\n",
    "    if type(text) == unicode:\n",
    "        return text.encode(\"ascii\", \"replace\")\n",
    "    else:\n",
    "        return text\n",
    "        \n",
    "def single_key_match(dfA, dfB, key, scorer=fuzz.ratio, cutoff=0.6): #Use force key for later\n",
    "    start = time.time()\n",
    "    \n",
    "    rowsA[key] = dfA[key].apply(decode_text) #If column is unicode, convert to string\n",
    "    rowsA[key] = dfB[key].apply(decode_text) #if column is unicode, convert to string\n",
    "    \n",
    "    rowsA = rowsA.drop_duplicates(subset=key)[key].T.to_dict().values() #Convert DF -> List of Dicts\n",
    "    rowsA = rowsB.drop_duplicates(subset=key)[key].T.to_dict().values() #Convert DF -> List of Dicts\n",
    "    \n",
    "    matches = pd.DataFrame() #Initialize empty dataframe to hold matches\n",
    "    \n",
    "    for rowA in rowsA:\n",
    "        max_score = 0\n",
    "        \n",
    "        for rowB in rowsB:                \n",
    "            score = scorer(rowA, rowB)\n",
    "            \n",
    "            if score > cutoff and score > max_score:\n",
    "                match = {key+\"A\": rowA, key+\"B\": rowB, key+\"_match_score\": score}\n",
    "                max_score = score\n",
    "            \n",
    "        if match is None:\n",
    "            match = {key+\"A\": keyA, key+\"B\": np.nan, key+\"_match_score\": np.nan}\n",
    "            \n",
    "        matches = matches.append([match], ignore_index=True)\n",
    "                              \n",
    "    end = time.time()\n",
    "    print \"Duration: \", round(end-start, 2), \"Seconds\"\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = match_single_key(test_us_news, test_ipeds, key=\"school\", cutoff=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Key Fuzzy Match (hierarchical) -- NEED TO FINISH WRITING THIS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_key_match(dfA, dfB, keys, scorer=fuzz.ratio, cutoffs=None):\n",
    "    start = time.time()\n",
    "    \n",
    "    if cutoffs is None:\n",
    "        cutoffs=[0.6] * len(keys) #Default to 0.6 for each key\n",
    "        \n",
    "    rowsA[key] = dfA[key].apply(decode_text) #If column is unicode, convert to string\n",
    "    rowsB[key] = dfB[key].apply(decode_text) #if column is unicode, convert to string\n",
    "        \n",
    "    rowsA[\"filter\"] = \" \" #Initialize Filter on DF A\n",
    "    rowsB[\"filter\"] = \" \" #Initialize Filter on DF B\n",
    "    \n",
    "    rowsA = rowsA.drop_duplicates(subset=keys)[keys+[\"filter\"]].T.to_dict().values() #Convert DF -> List of Dicts\n",
    "    rowsB = rowsB.drop_duplicates(subset=keys)[keys+[\"filter\"]].T.to_dict().values() #Convert DF -> List of Dicts    \n",
    "    \n",
    "    for key, cutoff in zip(keys, cutoffs): #Iterate through key variables (should be ordered most general -> specific)  \n",
    "        for rowA in [x for x in rowsA[key]]: #check list comprehension syntax\n",
    "            max_score = 0\n",
    "            \n",
    "            for rowB in [x for x in rowsB[key] if #FILTERING#]\n",
    "                score = scorer(rowA, rowB)\n",
    "            \n",
    "            if score > cutoff and score > max_score:\n",
    "                match = {key+\"A\": rowA, key+\"B\": rowB, key+\"_match_score\": score}\n",
    "                max_score = score\n",
    "            \n",
    "            if match is None:\n",
    "                match = {key+\"A\": rowA, key+\"B\": np.nan, key+\"_match_score\": np.nan}\n",
    "        \n",
    "            matches = matches.append([match], ignore_index=True)\n",
    "            matches = pd.merge() #Match and set filter\n",
    "            \n",
    "        rowA\n",
    "                              \n",
    "    end = time.time()\n",
    "    print \"Duration: \", round(end-start, 2), \"Seconds\"\n",
    "\n",
    "    return matches\n",
    "        \n",
    "##Function to Crate Crosswalk - OLD CODE TO INCORPORATE\n",
    "def create_xwalk(a, b, byvars, cutoffs, scorer):\n",
    "    b[\"filter\"] = b[[\"constant\"]+byvars].apply(lambda x: \"#\".join(x), axis=1).str.split(\"#\")\n",
    "    \n",
    "    a = a.drop_duplicates(subset=byvars)[byvars].T.to_dict().values()\n",
    "    b = b.drop_duplicates(subset=byvars)[byvars+[\"filter\"]].T.to_dict().values()\n",
    "    \n",
    "    for row in a:\n",
    "        for i in range(0, len(byvars)):\n",
    "            byvar = byvars[i]\n",
    "            cutoff = cutoffs[i]\n",
    "            if i==0:\n",
    "                choices = [x[byvar] for x in b]\n",
    "            else:\n",
    "                choices = [x[byvar] for x in b if row[\"filter\"]==x[\"filter\"][:i]]\n",
    "            \n",
    "            row[\"matched_\"+byvar] = fuzzy_match(row[byvar], choices, cutoff=cutoff, scorer=scorer)[1]\n",
    "            row[\"filter\"] = row[\"filter\"]+[row[\"matched_\"+byvar]]\n",
    "            \n",
    "    return pd.DataFrame(a).drop([\"constant\",\"filter\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = multi_key_match(test_us_news, test_ipeds, keys=[\"state\",\"city\",\"school\"])\n",
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Fuzzy Matching to Join Two Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fuzzy_merge(dfA, dfB, key, how=\"left\", scorer=fuzz.ratio, cutoff=None, force_single=False):\n",
    "    dfA[\"inA\"] = 1 #Flag rows existing in DF A\n",
    "    dfB[\"inB\"] = 1 #Flag rows existing in DF A\n",
    "    \n",
    "    merged = pd.merge(a, b, on=key, how=\"outer\") #Perform a regular (exact) join\n",
    "    \n",
    "    matched = merged[(merged.in_a.notnull()) & (merged.in_b.notnull())].copy() #Sift out exact matches\n",
    "    nomatchA = merged[(merged.in_a.notnull() | (merged.in_b.isnull()))].copy() #Sift out nonmatches from DF A\n",
    "    nomatchB = merged[(merged.in_a.isnull()) | (merged.in_b.notnull())].copy() #Sift out nomathches from DF B\n",
    "    \n",
    "    if nomatch_a.shape[0]==0 | nomatch_b.shape[0]==0: #No nomatches. Return matched DF and end.\n",
    "        return matched\n",
    "    \n",
    "    elif len(key) == 1: #Fuzzy Matching - Single Key\n",
    "        matches = \n",
    "    \n",
    "    elif force_single == True: #Fuzzy Matching - Multi Key Non-Heirarchical\n",
    "        pass\n",
    "    \n",
    "    else: #Fuzzy Matching - Multi Key Heirarchical\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fuzzy_merge(a, b, key, cutoff=0.6, how=\"left\", match_function=ratio_match):\n",
    "    a[\"in_a\"] = 1 #Flag rows existing in DF A\n",
    "    b[\"in_b\"] = 1 #Flag rows existing in DF B\n",
    "    \n",
    "    merged = pd.merge(a, b, on=key, how=\"outer\") #Perform a regular (exact) join\n",
    "    \n",
    "    matched = merged[(merged.in_a.notnull()) & (merged.in_b.notnull())].copy() #Sift out exact matches\n",
    "    nomatchA = merged[(merged.in_a.notnull() | (merged.in_b.isnull()))].copy() #Sift out nonmatches from DF A\n",
    "    nomatchB = merged[(merged.in_a.isnull()) | (merged.in_b.notnull())].copy() #Sift out nomathches from DF B\n",
    "    \n",
    "    if nomatch_a.shape[0]==0 | nomatch_b.shape[0]==0: #If no nonmatches in A or B, return matches & end\n",
    "        return matched\n",
    "\n",
    "    else: #Otherwise, proceed to fuzzy matching\n",
    "        crosswalk = \n",
    "        \n",
    "        \n",
    "    crosswalk = match_function(nonmatch_a, nonmatch_b, key=key, cutoff=cutoff) #Create key crosswalk\n",
    "        \n",
    "        fuzzy_merge1 = pd.merge(nonmatch_a, crosswalk, on=key+\"_A\", how=\"left\") #Match DF A to crosswalk on Key \n",
    "        fuzzy_merge2 = pd.merge(fuzzy_merge1, nonmatch_b, on=key+\"_B\", how=how) #Match DF A+Xwalk to DF B on Key B\n",
    "\n",
    "        return pd.concat([matched, fuzzy_merge_2], axis=0) #Append fuzzy matches to exact matches and return (MAKE DROPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
