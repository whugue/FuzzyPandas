{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prototype FuzzyPandas Functions using U.S. News and IPEDS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, let's read in the school ranking data scraped from usnews.com & do a little pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>school</th>\n",
       "      <th>score</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>PRINCETON UNIVERSITY</td>\n",
       "      <td>100 out of 100.</td>\n",
       "      <td>PRINCETON</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>HARVARD UNIVERSITY</td>\n",
       "      <td>99 out of 100.</td>\n",
       "      <td>CAMBRIDGE</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>YALE UNIVERSITY</td>\n",
       "      <td>97 out of 100.</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>COLUMBIA UNIVERSITY</td>\n",
       "      <td>95 out of 100.</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>STANFORD UNIVERSITY</td>\n",
       "      <td>95 out of 100.</td>\n",
       "      <td>STANFORD</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                category                school            score       city  \\\n",
       "0  National Universities  PRINCETON UNIVERSITY  100 out of 100.  PRINCETON   \n",
       "1  National Universities    HARVARD UNIVERSITY   99 out of 100.  CAMBRIDGE   \n",
       "2  National Universities       YALE UNIVERSITY   97 out of 100.  NEW HAVEN   \n",
       "3  National Universities   COLUMBIA UNIVERSITY   95 out of 100.   NEW YORK   \n",
       "4  National Universities   STANFORD UNIVERSITY   95 out of 100.   STANFORD   \n",
       "\n",
       "  state  \n",
       "0    NJ  \n",
       "1    MA  \n",
       "2    CT  \n",
       "3    NY  \n",
       "4    CA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_us_news(pickle):\n",
    "    df = pd.read_pickle(pickle)   \n",
    "    return pd.concat([us_news, df], axis=0, ignore_index=True)\n",
    "\n",
    "us_news = pd.DataFrame() #initialize empty data frame\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-national-universities.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-national-liberal-arts-colleges.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-midwest.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-north.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-south.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-west.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-midwest.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-north.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-south.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-west.pickle\")\n",
    "\n",
    "us_news[\"city\"] = us_news.location.apply(lambda x: x.split(\", \")[0].upper().strip()) #parse out city, to upper case\n",
    "us_news[\"state\"] = us_news.location.apply(lambda x: x.split(\", \")[1].upper().strip()) #parse out state, to upper case\n",
    "us_news[\"school\"] = us_news.school.apply(lambda x: x.upper().strip()) #school name to upper case\n",
    "\n",
    "us_news.drop(\"location\", axis=1, inplace=True) #drop original location (now that we've split out into city and state)\n",
    "us_news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in IPEDS Data & Preprocess. IPEDS Data can be downloaded for free here:**\n",
    "https://nces.ed.gov/ipeds/datacenter/Default.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unitid</th>\n",
       "      <th>school</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100636</td>\n",
       "      <td>COMMUNITY COLLEGE OF THE AIR FORCE</td>\n",
       "      <td>MONTGOMERY</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100654</td>\n",
       "      <td>ALABAMA A &amp; M UNIVERSITY</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100663</td>\n",
       "      <td>UNIVERSITY OF ALABAMA AT BIRMINGHAM</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100690</td>\n",
       "      <td>AMRIDGE UNIVERSITY</td>\n",
       "      <td>MONTGOMERY</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100706</td>\n",
       "      <td>UNIVERSITY OF ALABAMA IN HUNTSVILLE</td>\n",
       "      <td>HUNTSVILLE</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unitid                               school        city state\n",
       "0  100636   COMMUNITY COLLEGE OF THE AIR FORCE  MONTGOMERY    AL\n",
       "1  100654             ALABAMA A & M UNIVERSITY      NORMAL    AL\n",
       "2  100663  UNIVERSITY OF ALABAMA AT BIRMINGHAM  BIRMINGHAM    AL\n",
       "3  100690                   AMRIDGE UNIVERSITY  MONTGOMERY    AL\n",
       "4  100706  UNIVERSITY OF ALABAMA IN HUNTSVILLE  HUNTSVILLE    AL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipeds=pd.read_csv(\"example_data/ipeds/HD2014.csv\")[[\"UNITID\",\"INSTNM\",\"CITY\",\"STABBR\"]]\n",
    "\n",
    "ipeds.rename(columns={\"UNITID\":\"unitid\",\"INSTNM\":\"school\",\"CITY\":\"city\",\"STABBR\":\"state\"},inplace=True) \n",
    "#rename columns to match U.S. News Data\n",
    "\n",
    "ipeds[\"school\"] = ipeds.school.apply(lambda x: x.upper().strip()) #school to upper case\n",
    "ipeds[\"city\"] = ipeds.city.apply(lambda x: x.upper().strip()) #city to upper case\n",
    "ipeds[\"state\"] = ipeds.state.apply(lambda x: x.upper().strip()) #state to upper case\n",
    "ipeds.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Subset Data to Only NY and CT Schools for Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1506, 5) (142, 5)\n",
      "(7687, 4) (574, 4)\n"
     ]
    }
   ],
   "source": [
    "test_us_news = us_news[us_news.state.isin([\"CT\",\"NY\"])].copy()\n",
    "test_ipeds = ipeds[ipeds.state.isin([\"CT\",\"NY\"])].copy()\n",
    "\n",
    "print us_news.shape, test_us_news.shape\n",
    "print ipeds.shape, test_ipeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Fuzzy Matching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_text(text):\n",
    "    if type(text) == unicode:\n",
    "        return text.encode(\"ascii\", \"replace\")\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def get_best_match(value, choices, scorer, cutoff):\n",
    "    pass\n",
    "\n",
    "def match_keys(dfA, dfB, key, scorer=fuzz.ratio, cutoffs=0.6):\n",
    "    start = time.time()\n",
    "    \n",
    "    rowsA = dfA.drop_duplicates(subset=key)[key].tolist() #Convert Data Frame -> List of Dicts\n",
    "    rowsB = dfB.drop_duplicates(subset=key)[key].tolist() #Convert Data Frame -> List of Dicts\n",
    "    \n",
    "    for rowA in rowsA:\n",
    "        max_score = 0\n",
    "        \n",
    "        for rowB in rowsB:\n",
    "             score = scorer(decode_text(rowA[key]), decode_text(rowB[key]))\n",
    "                                   \n",
    "            if score > cutoff and score > max_score:\n",
    "                match = rowB[key]\n",
    "                max_score = score\n",
    "                \n",
    "        rowA[key+\"_match\"] = match\n",
    "        rowA[key+\"_match_score\"] = max_score\n",
    "        \n",
    "        end=time.time()\n",
    "        \n",
    "    return pd.DataFrame(rowA)\n",
    "\n",
    "##do this? or just append keys together?\n",
    "def hmatch_keys(dfA, dfB, keys, scorer=fuzz.ratio, cutoffs=None):\n",
    "    start = time.time()\n",
    "       \n",
    "    rowsA = dfA.drop_duplicates(subset=keys)[keys].T.to_dict().values() #Convert Data Frame -> List of Dicts\n",
    "    rowsB = dfB.drop_duplicates(subset=keys)[keys].T.to_dict().values() #Convert Data Frame -> List of Dicts\n",
    "    \n",
    "    if cutoffs is None:\n",
    "        cutoffs = [0.6] * len(keys)\n",
    "    \n",
    "    for key, cutoff in zip(keys, cutoffs): #Iterate Through Keys & Cutoffs\n",
    "        for rowA in rowsA: #Iterate Through Rows in first dataframe\n",
    "            \n",
    "            max_score = 0 #Initialize Best Match Score as 0\n",
    "            \n",
    "            for rowB in rowsB:\n",
    "                if (filter not in rowB.keys()) or (rowA[\"filter\"] == rowB[\"filter\"]):\n",
    "                    score = scorer(decode_text(rowA[key]), decode_text(rowB[key]))\n",
    "                                   \n",
    "                    if score > cutoff and score > max_score:\n",
    "                        match = rowB[key]\n",
    "                        max_score = score\n",
    "                \n",
    "                rowB[\"filter\"] = rowB.get(\"filter\", \"\")+\"-\"+rowB[key]\n",
    "            \n",
    "            rowA[key+\"_match\"] = match\n",
    "            rowA[key+\"_match_score\"] = max_score\n",
    "            rowA[\"filter\"] = rowA.get(\"filter\", \"\")+\"-\"+match\n",
    "        \n",
    "    end = time.time()\n",
    "    print \"Duration: \", end-start, \"Seconds\"\n",
    "        \n",
    "    return pd.DataFrame(rowsA).drop(\"filter\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fuzzy_merge(dfA, dfB, key, how=\"left\", scorer=fuzz.ratio, cutoff=None, force_single=False):\n",
    "    dfA[\"inA\"] = 1 #Flag rows existing in DF A\n",
    "    dfB[\"inB\"] = 1 #Flag rows existing in DF A\n",
    "    \n",
    "    merged = pd.merge(a, b, on=key, how=\"outer\") #Perform a regular (exact) join\n",
    "    \n",
    "    matched = merged[(merged.in_a.notnull()) & (merged.in_b.notnull())].copy() #Sift out exact matches\n",
    "    nomatchA = merged[(merged.in_a.notnull() | (merged.in_b.isnull()))].copy() #Sift out nonmatches from DF A\n",
    "    nomatchB = merged[(merged.in_a.isnull()) | (merged.in_b.notnull())].copy() #Sift out nomathches from DF B\n",
    "    \n",
    "    if nomatch_a.shape[0]==0 | nomatch_b.shape[0]==0: #No nomatches. Return matched DF and end.\n",
    "        return matched\n",
    "    \n",
    "    elif len(key) == 1: #Fuzzy Matching-Single Key\n",
    "        keyfile = single_key_match(dfA, dfB, key, cutoff)\n",
    "    \n",
    "    elif force_single == True: #Fuzzy Matching-Multi Key Non-Heirarchical\n",
    "        nomatchA[]\n",
    "\n",
    "    else: #Fuzzy Matching-Multi Key Heirarchical\n",
    "        pass\n",
    "    \n",
    "    fuzzyMerged1 = pd.merge(nomatchA, keyfile, on=key+\"A\", how=\"left\") #Match DF A to crosswalk on Key \n",
    "    fuzzyMerged2 = pd.merge(fuzzyMerged1, nomatchB, on=key+\"B\", how=how) #Match DF A+Xwalk to DF B on Key B\n",
    "\n",
    "    return pd.concat([matched, fuzzyMerged2], axis=0) #Append fuzzy matches to exact matches and return (MAKE DROPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
