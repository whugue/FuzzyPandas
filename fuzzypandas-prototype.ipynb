{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prototype FuzzyPandas Functions using U.S. News and IPEDS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import difflib\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, let's read in the school ranking data scraped from usnews.com & do a little pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>school</th>\n",
       "      <th>score</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>PRINCETON UNIVERSITY</td>\n",
       "      <td>100 out of 100.</td>\n",
       "      <td>PRINCETON</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>HARVARD UNIVERSITY</td>\n",
       "      <td>99 out of 100.</td>\n",
       "      <td>CAMBRIDGE</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>YALE UNIVERSITY</td>\n",
       "      <td>97 out of 100.</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>COLUMBIA UNIVERSITY</td>\n",
       "      <td>95 out of 100.</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>STANFORD UNIVERSITY</td>\n",
       "      <td>95 out of 100.</td>\n",
       "      <td>STANFORD</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                category                school            score       city  \\\n",
       "0  National Universities  PRINCETON UNIVERSITY  100 out of 100.  PRINCETON   \n",
       "1  National Universities    HARVARD UNIVERSITY   99 out of 100.  CAMBRIDGE   \n",
       "2  National Universities       YALE UNIVERSITY   97 out of 100.  NEW HAVEN   \n",
       "3  National Universities   COLUMBIA UNIVERSITY   95 out of 100.   NEW YORK   \n",
       "4  National Universities   STANFORD UNIVERSITY   95 out of 100.   STANFORD   \n",
       "\n",
       "  state  \n",
       "0    NJ  \n",
       "1    MA  \n",
       "2    CT  \n",
       "3    NY  \n",
       "4    CA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_us_news(pickle):\n",
    "    df = pd.read_pickle(pickle)   \n",
    "    return pd.concat([us_news, df], axis=0, ignore_index=True)\n",
    "\n",
    "us_news = pd.DataFrame() #initialize empty data frame\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-national-universities.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-national-liberal-arts-colleges.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-midwest.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-north.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-south.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-west.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-midwest.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-north.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-south.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-west.pickle\")\n",
    "\n",
    "us_news[\"city\"] = us_news.location.apply(lambda x: x.split(\", \")[0].upper().strip()) #parse out city, to upper case\n",
    "us_news[\"state\"] = us_news.location.apply(lambda x: x.split(\", \")[1].upper().strip()) #parse out state, to upper case\n",
    "us_news[\"school\"] = us_news.school.apply(lambda x: x.upper().strip()) #school name to upper case\n",
    "\n",
    "us_news.drop(\"location\", axis=1, inplace=True) #drop original location (now that we've split out into city and state)\n",
    "us_news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in IPEDS Data & Preprocess. IPEDS Data can be downloaded for free here:**\n",
    "https://nces.ed.gov/ipeds/datacenter/Default.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unitid</th>\n",
       "      <th>school</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100636</td>\n",
       "      <td>COMMUNITY COLLEGE OF THE AIR FORCE</td>\n",
       "      <td>MONTGOMERY</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100654</td>\n",
       "      <td>ALABAMA A &amp; M UNIVERSITY</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100663</td>\n",
       "      <td>UNIVERSITY OF ALABAMA AT BIRMINGHAM</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100690</td>\n",
       "      <td>AMRIDGE UNIVERSITY</td>\n",
       "      <td>MONTGOMERY</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100706</td>\n",
       "      <td>UNIVERSITY OF ALABAMA IN HUNTSVILLE</td>\n",
       "      <td>HUNTSVILLE</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unitid                               school        city state\n",
       "0  100636   COMMUNITY COLLEGE OF THE AIR FORCE  MONTGOMERY    AL\n",
       "1  100654             ALABAMA A & M UNIVERSITY      NORMAL    AL\n",
       "2  100663  UNIVERSITY OF ALABAMA AT BIRMINGHAM  BIRMINGHAM    AL\n",
       "3  100690                   AMRIDGE UNIVERSITY  MONTGOMERY    AL\n",
       "4  100706  UNIVERSITY OF ALABAMA IN HUNTSVILLE  HUNTSVILLE    AL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipeds=pd.read_csv(\"example_data/ipeds/HD2014.csv\")[[\"UNITID\",\"INSTNM\",\"CITY\",\"STABBR\"]]\n",
    "\n",
    "ipeds.rename(columns={\"UNITID\":\"unitid\",\"INSTNM\":\"school\",\"CITY\":\"city\",\"STABBR\":\"state\"},inplace=True) \n",
    "#rename columns to match U.S. News Data\n",
    "\n",
    "ipeds[\"school\"] = ipeds.school.apply(lambda x: x.upper().strip()) #school to upper case\n",
    "ipeds[\"city\"] = ipeds.city.apply(lambda x: x.upper().strip()) #city to upper case\n",
    "ipeds[\"state\"] = ipeds.state.apply(lambda x: x.upper().strip()) #state to upper case\n",
    "ipeds.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Instead, let's use FuzzyPandas to match each school in the U.S. News Data to it's CLOSEST, but not necessarily EXACT, U.S. News Match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1506, 5) (142, 5)\n",
      "(7687, 4) (574, 4)\n",
      "Index([u'category', u'school', u'score', u'city', u'state'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_us_news = us_news[us_news.state.isin([\"CT\",\"NY\"])].copy()\n",
    "test_ipeds = ipeds[ipeds.state.isin([\"CT\",\"NY\"])].copy()\n",
    "\n",
    "print us_news.shape, test_us_news.shape\n",
    "print ipeds.shape, test_ipeds.shape\n",
    "\n",
    "print test_us_news.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_matches(a, b, byvar):\n",
    "    start = time.time()\n",
    "    \n",
    "    matches = pd.DataFrame(a[byvar].unique())\n",
    "    matches.rename(columns={0:byvar}, inplace=True)\n",
    "    try:\n",
    "        matches[\"matched\"] = matches[byvar].map(lambda x: difflib.get_close_matches(x, b[byvar].unique(), n=1, cutoff=0.6))\n",
    "    except IndexError:\n",
    "        matches[\"matched\"] = np.nan\n",
    "    \n",
    "    end = time.time()\n",
    "    print \"Duration: \", end-start, \"Seconds.\"\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_xwalk(a, b, byvars): \n",
    "    start=time.time()\n",
    "    a = a.drop_duplicates(subset=byvars)[byvars].T.to_dict().values()\n",
    "    b = b.drop_duplicates(subset=byvars)[byvars].T.to_dict().values()\n",
    "\n",
    "    for i, row in enumerate(a):\n",
    "        states = [x[\"state\"] for x in b]\n",
    "        row[\"matched_state\"] = difflib.get_close_matches(row[\"state\"], states, n=1, cutoff=0.6)[0]\n",
    "        \n",
    "        cities = [x[\"city\"] for x in b if x[\"state\"]==row[\"matched_state\"]]\n",
    "        row[\"matched_city\"] = difflib.get_close_matches(row[\"city\"], cities, n=1, cutoff=0.6)[0]\n",
    "        \n",
    "        schools = [x[\"school\"] for x in b if x[\"state\"]==row[\"matched_state\"] and x[\"city\"]==row[\"matched_city\"]]\n",
    "        row[\"matched_school\"] = difflib.get_close_matches(row[\"school\"], schools, n=1, cutoff=0.6)\n",
    "            \n",
    "    end = time.time()\n",
    "    print \"Duration: \",end-start, \"Seconds.\"\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ecf109ddfc2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_xwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_us_news\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ipeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"state\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"city\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"school\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-ecf109ddfc2d>\u001b[0m in \u001b[0;36mcreate_xwalk\u001b[0;34m(a, b, byvars)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"one\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"one\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/willhuguenin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2297\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2299\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/willhuguenin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2366\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2367\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/willhuguenin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2523\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2525\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/willhuguenin/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   2739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2741\u001b[0;31m         raise ValueError('Length of values does not match length of '\n\u001b[0m\u001b[1;32m   2742\u001b[0m                          'index')\n\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "def create_xwalk(a, b, byvars): \n",
    "    start=time.time()\n",
    "    \n",
    "    a[\"one\"] = \"1\"\n",
    "    b[\"one\"] = \"1\"\n",
    "\n",
    "    a[\"filter\"] = a[\"one\"]\n",
    "    b[\"filter\"] = b[[\"one\"]+byvars].apply(lambda x: \"/#/\".join(x), axis=1).str.split(\"/#/\")\n",
    "    \n",
    "    #a = a[byvars+[\"filter\"]].T.to_dict.values()\n",
    "    #b = b[byvars+[\"filter\"]].T.to_dict.values()\n",
    "\n",
    "    return a, b\n",
    "\n",
    "test = create_xwalk(test_us_news, test_ipeds, [\"state\",\"city\",\"school\"])\n",
    "print test[0].head(5)\n",
    "print \"\"\n",
    "print test[1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    \n",
    "    a[\"filter\"] = \"0\" #initialize filter\n",
    "    b[\"filter\"] = \"0\" #initialize filter\n",
    "    \n",
    "    a = a.drop_duplicates(subset=byvars)[byvars+[\"filter\"]].T.to_dict.values()\n",
    "    b = b.drop_duplicates(subset=byvars)[byvars+[\"filter\"]]\n",
    "    \n",
    "    for byvar, cutoff in zip(byvar, cutoffs):   \n",
    "        for row in a:\n",
    "            possible_matches = [x[byvar] for x in b if x[\"filter\"]==row[\"filter\"]]\n",
    "            \n",
    "            try:\n",
    "                row[\"matched_\"+byvar] = difflib.get_close_matches(row[byvar], possible_matches, n=1, cutoff=cutoff)[0]\n",
    "            except IndexError:\n",
    "                row[\"matched_\"+byvar] = \" \"\n",
    "                \n",
    "        possible_matches = \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for row in a[:4]:\n",
    "        for byvar, cutoff in zip(byvars, cutoffs):            \n",
    "            possible_matches = [x[byvar] for x in b if x[\"filter\"]==row[\"filter\"]]\n",
    " \n",
    "\n",
    "            \n",
    "            row[\"filter\"] = row[\"filter\"]+\"-\"+row[\"matched_\"+byvar]\n",
    "            for item in b:\n",
    "                item[\"filter\"] = item[\"filter\"]+\"-\"+item[byvar] #make this less brute force later?\n",
    "                \n",
    "            print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_us_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Function only implimented if multiple byvars / heirarchical problem\n",
    "##Byvars = \n",
    "def create_xwalk(a, b, byvars, cutoffs):\n",
    "    xwalk = get_matches(a=a, b=b, byvar=byvars[0], cutoff=cutoff[0])\n",
    "    \n",
    "    for states in zip(xwalk[\"state_A\"], xwalk[\"state_B\"]):\n",
    "        slice_a\n",
    "        slice_b\n",
    "        xwalk = get_matches \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_xwalk():\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fuzzy_merge(a, b, fuzz_on, how=\"left\", cutoffs=0.6):\n",
    "    ##First Do a Regular Join\n",
    "    a[\"in_a\"] = 1\n",
    "    b[\"in_b\"] = 1\n",
    "    \n",
    "    merged = pd.merge(a, b, on=fuzz_on, how=\"outer\")\n",
    "\n",
    "    matched = merged[(merged.in_a.notnull()) & (merged.in_b.notnull())].copy()\n",
    "    matched[\"match_score\"] = 1.0 #Score for all exact matches is 1.0 by definition\n",
    "    \n",
    "    nomatch_a = merged[(merged.in_a.notnull() | (merged.in_b.isnull()))].copy()\n",
    "    nomatch_b = merged[(merged.in_a.isnull()) | (merged.in_b.notnull())].copy()\n",
    "    \n",
    "    ##If no nomatched, we're done - return dataframe\n",
    "    if nomatch_a.shape[0]==0 | nomatch_b.shape[0]==0:\n",
    "        return matched\n",
    "    \n",
    "    ##Otherwise, Proceed to fuzzy matching. Fuzzy Merge on first by-variable, than second, etc.\n",
    "    else:\n",
    "        fuzzy_matches = \n",
    "        \n",
    "        fuzzy_matches = pd.DataFrame() #initialize empty dataframe to hold matches\n",
    "        \n",
    "        i = 0 #Set Number of Iterations to 0\n",
    "        slice_a = nomatch_a.copy()\n",
    "        slice_b = nomatch_b.copy()\n",
    "        \n",
    "        while i < len(fuzz_on):\n",
    "            byvar = fuzz_on[i]\n",
    "            cutoff = cutoffs[i]\n",
    "            \n",
    "            xwalk = create_xwalk(slice_a, slice_b, byvar=fuzz_on[i], cutoff=cutoffs[i])\n",
    "            \n",
    "            for \n",
    "            \n",
    "            list_a = slice_a[byvar].unique().tolist()\n",
    "            list_b = slice_a[byvar].unique().tolist()\n",
    "            \n",
    "            crosswalk = \n",
    "            \n",
    "            i+=1\n",
    "        \n",
    "        \n",
    "        ##Merge Dataframe A Nonmatches to Dataframe B Nonmatches. Append to Exact Matches and Return\n",
    "        nomatch_b.rename(columns={\"byvar\":\"matchvar\"})\n",
    "        fuzzy_merge1 = pd.merge(nomatch_a, fuzzy_matches, on=\"byvar\", how=\"left\")\n",
    "        fuzzy_merge2 = pd.merge(nomatch_a, nomatch_a, on=\"matchvar\", how=how)\n",
    "        \n",
    "        return pd.concat([matched, fuzzy_merge2], axis=0).drop([\"byvar\", \"merged\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "In [23]: import difflib \n",
    "\n",
    "In [24]: difflib.get_close_matches\n",
    "Out[24]: <function difflib.get_close_matches>\n",
    "\n",
    "In [25]: df2.index = df2.index.map(lambda x: difflib.get_close_matches(x, df1.index)[0])\n",
    "\n",
    "In [26]: df2\n",
    "Out[26]: \n",
    "      letter\n",
    "one        a\n",
    "two        b\n",
    "three      c\n",
    "four       d\n",
    "five       e\n",
    "\n",
    "In [31]: df1.join(df2)\n",
    "Out[31]: \n",
    "       number letter\n",
    "one         1      a\n",
    "two         2      b\n",
    "three       3      c\n",
    "four        4      d\n",
    "five        5      e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "test = nyc_us_news[\"school\"].apply(find_match(b=nyc_ipeds.school.unique(), score_cutoff=0.6))\n",
    "\n",
    "end = time.time()\n",
    "print end-start\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        fuzzy_matches=[]\n",
    "        for each in nomatch_a.byvar.unique():\n",
    "            fuzzy_match = process.extractOne(each, nomatch_b.byvar.unique(), score_cutoff=score_cutoff)\n",
    "            \n",
    "            if fuzzy_match==None:\n",
    "                fuzzy_matches.append({\"byvar\": each, \"matchvar\": np.nan, \"fuzzy_match_score\": np.nan})\n",
    "            else:\n",
    "                fuzzy_matches.append({\"byvar\": each, \"matchvar\": fuzzy_match[0], \"fuzzy_match_score\": fuzzy_match[1]})\n",
    "                \n",
    "        fuzzy_matches = pd.DataFrame(fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Function to Do a Fuzzy Match\n",
    "##This on takes way to long to run; need to find a way to make more efficient\n",
    "def fuzzy_merge(a, b, fuzz_on, how=\"left\", score_cutoff=0.6):\n",
    "    merged = exact_merge(a=a, b=b, exact_on=fuzz_on) #Run Exact Merge\n",
    "    matched = merged[0] #Pull Out matches\n",
    "    nomatch = merged[1] #Pull Out Nonmatched\n",
    "    \n",
    "    ##If No Nonmatched, we're done :). Just Return Matched Dataframe\n",
    "    if nomatch.shape[0] == 0: #if no non-matches, just return the merged dataframe\n",
    "        return matched\n",
    "    \n",
    "    ##Otherwise, Proceed to Fuzzy Matching Non-Matches\n",
    "    else:\n",
    "        nomatch_a = nomatch[nomatch.in_a==1].copy()\n",
    "        nomatch_b = nomatch[nomatch.in_b==1].copy()\n",
    "        \n",
    "        ##If Multiple By-Variables, String them Together for Fuzzy Merge. Otherwise, Use Single By-Varaiable\n",
    "        if len(fuzz_on) > 1:\n",
    "            nomatch_a[\"byvar\"] = nomatch_a[fuzz_on].apply(lambda x: \" \".join(x), axis=1)\n",
    "            nomatch_b[\"byvar\"] = nomatch_b[fuzz_on].apply(lambda x: \" \".join(x), axis=1)\n",
    "        else:\n",
    "            nomatch_a[\"byvar\"] = nomatch_a[fuzz_on]\n",
    "            nomatch_b[\"byvar\"] = nomatch_b[fuzz_on]\n",
    "        \n",
    "        ##For Each Nonmatch in Dataframe A, Use FuzzyWuzzy to Match to Closest Dataframe B Nonmatched\n",
    "        fuzzy_matches=[]\n",
    "        for each in nomatch_a.byvar.unique():\n",
    "            fuzzy_match = process.extractOne(each, nomatch_b.byvar.unique(), score_cutoff=score_cutoff)\n",
    "            \n",
    "            if fuzzy_match==None:\n",
    "                fuzzy_matches.append({\"byvar\": each, \"matchvar\": np.nan, \"fuzzy_match_score\": np.nan})\n",
    "            else:\n",
    "                fuzzy_matches.append({\"byvar\": each, \"matchvar\": fuzzy_match[0], \"fuzzy_match_score\": fuzzy_match[1]})\n",
    "                \n",
    "        fuzzy_matches = pd.DataFrame(fuzzy_matches)\n",
    "        \n",
    "        ##Merge Dataframe A Nonmatches to Dataframe B Nonmatches. Append to Exact Matches and Return\n",
    "        nomatch_b.rename(columns={\"byvar\":\"matchvar\"})\n",
    "        fuzzy_merge1 = pd.merge(nomatch_a, fuzzy_matches, on=\"byvar\", how=\"left\")\n",
    "        fuzzy_merge2 = pd.merge(nomatch_a, nomatch_a, on=\"matchvar\", how=how)\n",
    "        \n",
    "        return pd.concat([matched, fuzzy_merge2], axis=0).drop([\"byvar\", \"merged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny_us_news = us_news[us_news.state==\"NY\"].copy()\n",
    "ny_ipeds = ipeds[ipeds.state==\"NY\"].copy()\n",
    "\n",
    "print ny_us_news.shape, ny_ipeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny_test = fuzzy_merge(us_news, ipeds, fuzz_on=[\"state\",\"city\",\"school\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Second Attempt :)\n",
    "\n",
    "\n",
    "##Function to Create Fuzzy Matches By-Variable Crosswalk Between List of Values A and List of Values B\n",
    "def create_crosswalk(list_a, list_b, byvar, cutoff):\n",
    "    matches = []\n",
    "    \n",
    "    for item in list_a:\n",
    "        match = process.extractOne(each, list_b, score_cutoff=cutoff)\n",
    "        \n",
    "        if fuzz_match==None:\n",
    "            matches.append({\"byvar\": each, \"matchvar\": np.nan, \"fuzzy_match_score\": np.nan})\n",
    "        else:\n",
    "            matches.append({\"byvar\": each, \"matchvar\": fuzzy_match[0], \"fuzzy_match_score\": fuzzy_match[1]})\n",
    "      \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "\n",
    "##Function to Impliment the Fuzzy Merge\n",
    "def fuzzy_merge(a, b, fuzz_on, how=\"left\", cutoffs):\n",
    "\n",
    "    ##First, Do a Regular Pandas Join & Output Matches and Nonmatches\n",
    "    a[\"in_a\"] = 1 #Set Flag for Being in DF A\n",
    "    b[\"in_b\"] = 1 #Set Flag for Being in DF B\n",
    "    \n",
    "    merged = pd.merge(a, b, how=\"outer\", on=on)\n",
    "    \n",
    "    matched = merged[(merged.in_a.notnull()) & (merged.in_b.notnull())].copy()\n",
    "    matched[\"fuzz_match_score\"] = 1.0 #score for all matched is 1.0 by default\n",
    "    \n",
    "    nomatch_a = merged[(merged.in_a.notnull()) & (merged.in_b.isnull())].copy()\n",
    "    nomatch_b = merged[(merged.in_a.isnull()) & (merged.in_b.notnull())].copy()\n",
    "    \n",
    "    ##If no nonmatches, we're done :). Return Matched Dataframe\n",
    "    if nomatch_a.shape[0]==0 or nomatch_b.shape[0]==0:\n",
    "        return matched\n",
    "    \n",
    "    ##Otherwise, Proceed to fuzzy matching. Fuzzy Merge on first by-variable, than second, etc.\n",
    "    else:\n",
    "        fuzzy_matches = pd.DataFrame() #initialize empty dataframe to hold matches\n",
    "        \n",
    "        i = 0\n",
    "        slice_a = nomatch_a.copy()\n",
    "        slice_b = nomatch_b.copy()\n",
    "        \n",
    "        while i < len(fuzz_on):\n",
    "            byvar=fuzz_on[i]\n",
    "            cutoff = cutoffs[i]\n",
    "            \n",
    "            list_a = slice_a[byvar].unique().tolist()\n",
    "            list_b = slice_a[byvar].unique().tolist()\n",
    "            \n",
    "            crosswalk = \n",
    "            \n",
    "            i+=1\n",
    "        \n",
    "        \n",
    "        ##Merge Dataframe A Nonmatches to Dataframe B Nonmatches. Append to Exact Matches and Return\n",
    "        nomatch_b.rename(columns={\"byvar\":\"matchvar\"})\n",
    "        fuzzy_merge1 = pd.merge(nomatch_a, fuzzy_matches, on=\"byvar\", how=\"left\")\n",
    "        fuzzy_merge2 = pd.merge(nomatch_a, nomatch_a, on=\"matchvar\", how=how)\n",
    "        \n",
    "        return pd.concat([matched, fuzzy_merge2], axis=0).drop([\"byvar\", \"merged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partial_fuzzy_merge(a, b, exact_on, fuzz_on, how=\"left\", cutoffs):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
