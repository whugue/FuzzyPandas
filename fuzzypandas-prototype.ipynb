{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prototype FuzzyPandas Functions using U.S. News and IPEDS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, let's read in the school ranking data scraped from usnews.com & do a little pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>school</th>\n",
       "      <th>score</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>PRINCETON UNIVERSITY</td>\n",
       "      <td>100 out of 100.</td>\n",
       "      <td>PRINCETON</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>HARVARD UNIVERSITY</td>\n",
       "      <td>99 out of 100.</td>\n",
       "      <td>CAMBRIDGE</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>YALE UNIVERSITY</td>\n",
       "      <td>97 out of 100.</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>COLUMBIA UNIVERSITY</td>\n",
       "      <td>95 out of 100.</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>STANFORD UNIVERSITY</td>\n",
       "      <td>95 out of 100.</td>\n",
       "      <td>STANFORD</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                category                school            score       city  \\\n",
       "0  National Universities  PRINCETON UNIVERSITY  100 out of 100.  PRINCETON   \n",
       "1  National Universities    HARVARD UNIVERSITY   99 out of 100.  CAMBRIDGE   \n",
       "2  National Universities       YALE UNIVERSITY   97 out of 100.  NEW HAVEN   \n",
       "3  National Universities   COLUMBIA UNIVERSITY   95 out of 100.   NEW YORK   \n",
       "4  National Universities   STANFORD UNIVERSITY   95 out of 100.   STANFORD   \n",
       "\n",
       "  state  \n",
       "0    NJ  \n",
       "1    MA  \n",
       "2    CT  \n",
       "3    NY  \n",
       "4    CA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_us_news(pickle):\n",
    "    df = pd.read_pickle(pickle)   \n",
    "    return pd.concat([us_news, df], axis=0, ignore_index=True)\n",
    "\n",
    "us_news = pd.DataFrame() #initialize empty data frame\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-national-universities.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-national-liberal-arts-colleges.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-midwest.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-north.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-south.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-colleges-west.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-midwest.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-north.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-south.pickle\")\n",
    "us_news = read_us_news(\"example_data/us_news/usnews-ranking-regional-universities-west.pickle\")\n",
    "\n",
    "us_news[\"city\"] = us_news.location.apply(lambda x: x.split(\", \")[0].upper().strip()) #parse out city, to upper case\n",
    "us_news[\"state\"] = us_news.location.apply(lambda x: x.split(\", \")[1].upper().strip()) #parse out state, to upper case\n",
    "us_news[\"school\"] = us_news.school.apply(lambda x: x.upper().strip()) #school name to upper case\n",
    "\n",
    "us_news.drop(\"location\", axis=1, inplace=True) #drop original location (now that we've split out into city and state)\n",
    "us_news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in IPEDS Data & Preprocess. IPEDS Data can be downloaded for free here:**\n",
    "https://nces.ed.gov/ipeds/datacenter/Default.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unitid</th>\n",
       "      <th>school</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100636</td>\n",
       "      <td>COMMUNITY COLLEGE OF THE AIR FORCE</td>\n",
       "      <td>MONTGOMERY</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100654</td>\n",
       "      <td>ALABAMA A &amp; M UNIVERSITY</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100663</td>\n",
       "      <td>UNIVERSITY OF ALABAMA AT BIRMINGHAM</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100690</td>\n",
       "      <td>AMRIDGE UNIVERSITY</td>\n",
       "      <td>MONTGOMERY</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100706</td>\n",
       "      <td>UNIVERSITY OF ALABAMA IN HUNTSVILLE</td>\n",
       "      <td>HUNTSVILLE</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unitid                               school        city state\n",
       "0  100636   COMMUNITY COLLEGE OF THE AIR FORCE  MONTGOMERY    AL\n",
       "1  100654             ALABAMA A & M UNIVERSITY      NORMAL    AL\n",
       "2  100663  UNIVERSITY OF ALABAMA AT BIRMINGHAM  BIRMINGHAM    AL\n",
       "3  100690                   AMRIDGE UNIVERSITY  MONTGOMERY    AL\n",
       "4  100706  UNIVERSITY OF ALABAMA IN HUNTSVILLE  HUNTSVILLE    AL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipeds=pd.read_csv(\"example_data/ipeds/HD2014.csv\")[[\"UNITID\",\"INSTNM\",\"CITY\",\"STABBR\"]]\n",
    "\n",
    "ipeds.rename(columns={\"UNITID\":\"unitid\",\"INSTNM\":\"school\",\"CITY\":\"city\",\"STABBR\":\"state\"},inplace=True) \n",
    "#rename columns to match U.S. News Data\n",
    "\n",
    "ipeds[\"school\"] = ipeds.school.apply(lambda x: x.upper().strip()) #school to upper case\n",
    "ipeds[\"city\"] = ipeds.city.apply(lambda x: x.upper().strip()) #city to upper case\n",
    "ipeds[\"state\"] = ipeds.state.apply(lambda x: x.upper().strip()) #state to upper case\n",
    "ipeds.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Instead, let's use FuzzyPandas to match each school in the U.S. News Data to it's CLOSEST, but not necessarily EXACT, U.S. News Match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 5)\n",
      "(574, 4)\n"
     ]
    }
   ],
   "source": [
    "test_us_news = us_news[us_news.state.isin([\"CT\",\"NY\"])].copy()\n",
    "test_ipeds = ipeds[ipeds.state.isin([\"CT\",\"NY\"])].copy()\n",
    "\n",
    "print test_us_news.shape\n",
    "print test_ipeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_matches(a, b, byvar, cutoff):\n",
    "    matches = pd.DataFrame(a[byvar].unique())\n",
    "    matches.rename(columns={0 : byvar+\"_A\"}, inplace=True)\n",
    "    \n",
    "    matches[\"matched\"] = matches[byvar+\"_A\"].map(lambda x: process.extractOne(x, b[byvar].unique(), score_cutoff=cutoff))\n",
    "    matches[byvar+\"_B\"] = matches[\"matched\"].apply(lambda x: x[0])\n",
    "    matches[byvar+\"_match_score\"] = matches[\"matched\"].apply(lambda x: x[1])\n",
    "    \n",
    "    return matches[[byvar+\"_A\", byvar+\"_B\", byvar+\"_match_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "[{'category': 'National Universities', 'city': u'NEW HAVEN', 'school': u'YALE UNIVERSITY', 'score': u'97 out of 100.', 'state': u'CT'}, {'category': 'National Universities', 'city': u'NEW YORK', 'school': u'COLUMBIA UNIVERSITY', 'score': u'95 out of 100.', 'state': u'NY'}, {'category': 'National Liberal Arts Colleges', 'city': u'NEW BRITAIN', 'school': u'CHARTER OAK STATE COLLEGE', 'score': 'not ranked', 'state': u'CT'}, {'category': 'Regional Universities North', 'city': u'AMHERST', 'school': u'DAEMEN COLLEGE', 'score': 'not ranked', 'state': u'NY'}, {'category': 'National Universities', 'city': u'ITHACA', 'school': u'CORNELL UNIVERSITY', 'score': u'84 out of 100.', 'state': u'NY'}]\n"
     ]
    }
   ],
   "source": [
    "test = test_us_news.T.to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_xwalk(a, b, byvars, cutoffs): #here we are assuming multiple by-variables, heirarchical fuzzy matching\n",
    "    start = time.time() #Initialize Start Time\n",
    "    a = a.drop_duplicates(subset=byvars)[byvars].T.to_dict().values()\n",
    "    b = b.drop_duplicates(subset=byvars)[byvars]\n",
    "\n",
    "    end = time.time()\n",
    "    print \"Duration: \", (end-start), \"seconds.\"\n",
    "    \n",
    "    for row in a:\n",
    "        row[\"matched\"] = process.extractOne(row[\"state\"], b[\"state\"].unique(), score_cutoff=cutoffs[0])[0]\n",
    "        \n",
    "        #?\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration:  0.0160610675812 seconds.\n",
      "[{'city': u'NEWBURGH', 'state': u'NY', 'state_match': 'NY'}, {'city': u'NEW HAVEN', 'state': u'CT', 'state_match': 'CT'}, {'city': u'NEW YORK', 'state': u'NY', 'state_match': 'NY'}, {'city': u'NEW BRITAIN', 'state': u'CT', 'state_match': 'CT'}, {'city': u'HEMPSTEAD', 'state': u'NY', 'state_match': 'NY'}, {'city': u'THROGGS NECK', 'state': u'NY', 'state_match': 'NY'}, {'city': u'LOUDONVILLE', 'state': u'NY', 'state_match': 'NY'}, {'city': u'ALFRED', 'state': u'NY', 'state_match': 'NY'}, {'city': u'BROOKLYN HEIGHTS', 'state': u'NY', 'state_match': 'NY'}, {'city': u'ALBANY', 'state': u'NY', 'state_match': 'NY'}]\n"
     ]
    }
   ],
   "source": [
    "print create_xwalk(test_us_news, test_ipeds, byvars=[\"state\",\"city\"], cutoffs=[0.6, 0.6])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>school</th>\n",
       "      <th>score</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>YALE UNIVERSITY</td>\n",
       "      <td>97 out of 100.</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>COLUMBIA UNIVERSITY</td>\n",
       "      <td>95 out of 100.</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>CORNELL UNIVERSITY</td>\n",
       "      <td>84 out of 100.</td>\n",
       "      <td>ITHACA</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>NEW YORK UNIVERSITY</td>\n",
       "      <td>67 out of 100.</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>National Universities</td>\n",
       "      <td>UNIVERSITY OF ROCHESTER</td>\n",
       "      <td>66 out of 100.</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category                   school           score       city  \\\n",
       "2   National Universities          YALE UNIVERSITY  97 out of 100.  NEW HAVEN   \n",
       "3   National Universities      COLUMBIA UNIVERSITY  95 out of 100.   NEW YORK   \n",
       "14  National Universities       CORNELL UNIVERSITY  84 out of 100.     ITHACA   \n",
       "31  National Universities      NEW YORK UNIVERSITY  67 out of 100.   NEW YORK   \n",
       "32  National Universities  UNIVERSITY OF ROCHESTER  66 out of 100.  ROCHESTER   \n",
       "\n",
       "   state  \n",
       "2     CT  \n",
       "3     NY  \n",
       "14    NY  \n",
       "31    NY  \n",
       "32    NY  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_us_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Function only implimented if multiple byvars / heirarchical problem\n",
    "##Byvars = \n",
    "def create_xwalk(a, b, byvars, cutoffs):\n",
    "    xwalk = get_matches(a=a, b=b, byvar=byvars[0], cutoff=cutoff[0])\n",
    "    \n",
    "    for states in zip(xwalk[\"state_A\"], xwalk[\"state_B\"]):\n",
    "        slice_a\n",
    "        slice_b\n",
    "        xwalk = get_matches \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_xwalk():\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fuzzy_merge(a, b, fuzz_on, how=\"left\", cutoffs=0.6):\n",
    "    ##First Do a Regular Join\n",
    "    a[\"in_a\"] = 1\n",
    "    b[\"in_b\"] = 1\n",
    "    \n",
    "    merged = pd.merge(a, b, on=fuzz_on, how=\"outer\")\n",
    "\n",
    "    matched = merged[(merged.in_a.notnull()) & (merged.in_b.notnull())].copy()\n",
    "    matched[\"match_score\"] = 1.0 #Score for all exact matches is 1.0 by definition\n",
    "    \n",
    "    nomatch_a = merged[(merged.in_a.notnull() | (merged.in_b.isnull()))].copy()\n",
    "    nomatch_b = merged[(merged.in_a.isnull()) | (merged.in_b.notnull())].copy()\n",
    "    \n",
    "    ##If no nomatched, we're done - return dataframe\n",
    "    if nomatch_a.shape[0]==0 | nomatch_b.shape[0]==0:\n",
    "        return matched\n",
    "    \n",
    "    ##Otherwise, Proceed to fuzzy matching. Fuzzy Merge on first by-variable, than second, etc.\n",
    "    else:\n",
    "        fuzzy_matches = \n",
    "        \n",
    "        fuzzy_matches = pd.DataFrame() #initialize empty dataframe to hold matches\n",
    "        \n",
    "        i = 0 #Set Number of Iterations to 0\n",
    "        slice_a = nomatch_a.copy()\n",
    "        slice_b = nomatch_b.copy()\n",
    "        \n",
    "        while i < len(fuzz_on):\n",
    "            byvar = fuzz_on[i]\n",
    "            cutoff = cutoffs[i]\n",
    "            \n",
    "            xwalk = create_xwalk(slice_a, slice_b, byvar=fuzz_on[i], cutoff=cutoffs[i])\n",
    "            \n",
    "            for \n",
    "            \n",
    "            list_a = slice_a[byvar].unique().tolist()\n",
    "            list_b = slice_a[byvar].unique().tolist()\n",
    "            \n",
    "            crosswalk = \n",
    "            \n",
    "            i+=1\n",
    "        \n",
    "        \n",
    "        ##Merge Dataframe A Nonmatches to Dataframe B Nonmatches. Append to Exact Matches and Return\n",
    "        nomatch_b.rename(columns={\"byvar\":\"matchvar\"})\n",
    "        fuzzy_merge1 = pd.merge(nomatch_a, fuzzy_matches, on=\"byvar\", how=\"left\")\n",
    "        fuzzy_merge2 = pd.merge(nomatch_a, nomatch_a, on=\"matchvar\", how=how)\n",
    "        \n",
    "        return pd.concat([matched, fuzzy_merge2], axis=0).drop([\"byvar\", \"merged\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "In [23]: import difflib \n",
    "\n",
    "In [24]: difflib.get_close_matches\n",
    "Out[24]: <function difflib.get_close_matches>\n",
    "\n",
    "In [25]: df2.index = df2.index.map(lambda x: difflib.get_close_matches(x, df1.index)[0])\n",
    "\n",
    "In [26]: df2\n",
    "Out[26]: \n",
    "      letter\n",
    "one        a\n",
    "two        b\n",
    "three      c\n",
    "four       d\n",
    "five       e\n",
    "\n",
    "In [31]: df1.join(df2)\n",
    "Out[31]: \n",
    "       number letter\n",
    "one         1      a\n",
    "two         2      b\n",
    "three       3      c\n",
    "four        4      d\n",
    "five        5      e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "test = nyc_us_news[\"school\"].apply(find_match(b=nyc_ipeds.school.unique(), score_cutoff=0.6))\n",
    "\n",
    "end = time.time()\n",
    "print end-start\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        fuzzy_matches=[]\n",
    "        for each in nomatch_a.byvar.unique():\n",
    "            fuzzy_match = process.extractOne(each, nomatch_b.byvar.unique(), score_cutoff=score_cutoff)\n",
    "            \n",
    "            if fuzzy_match==None:\n",
    "                fuzzy_matches.append({\"byvar\": each, \"matchvar\": np.nan, \"fuzzy_match_score\": np.nan})\n",
    "            else:\n",
    "                fuzzy_matches.append({\"byvar\": each, \"matchvar\": fuzzy_match[0], \"fuzzy_match_score\": fuzzy_match[1]})\n",
    "                \n",
    "        fuzzy_matches = pd.DataFrame(fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Function to Do a Fuzzy Match\n",
    "##This on takes way to long to run; need to find a way to make more efficient\n",
    "def fuzzy_merge(a, b, fuzz_on, how=\"left\", score_cutoff=0.6):\n",
    "    merged = exact_merge(a=a, b=b, exact_on=fuzz_on) #Run Exact Merge\n",
    "    matched = merged[0] #Pull Out matches\n",
    "    nomatch = merged[1] #Pull Out Nonmatched\n",
    "    \n",
    "    ##If No Nonmatched, we're done :). Just Return Matched Dataframe\n",
    "    if nomatch.shape[0] == 0: #if no non-matches, just return the merged dataframe\n",
    "        return matched\n",
    "    \n",
    "    ##Otherwise, Proceed to Fuzzy Matching Non-Matches\n",
    "    else:\n",
    "        nomatch_a = nomatch[nomatch.in_a==1].copy()\n",
    "        nomatch_b = nomatch[nomatch.in_b==1].copy()\n",
    "        \n",
    "        ##If Multiple By-Variables, String them Together for Fuzzy Merge. Otherwise, Use Single By-Varaiable\n",
    "        if len(fuzz_on) > 1:\n",
    "            nomatch_a[\"byvar\"] = nomatch_a[fuzz_on].apply(lambda x: \" \".join(x), axis=1)\n",
    "            nomatch_b[\"byvar\"] = nomatch_b[fuzz_on].apply(lambda x: \" \".join(x), axis=1)\n",
    "        else:\n",
    "            nomatch_a[\"byvar\"] = nomatch_a[fuzz_on]\n",
    "            nomatch_b[\"byvar\"] = nomatch_b[fuzz_on]\n",
    "        \n",
    "        ##For Each Nonmatch in Dataframe A, Use FuzzyWuzzy to Match to Closest Dataframe B Nonmatched\n",
    "        fuzzy_matches=[]\n",
    "        for each in nomatch_a.byvar.unique():\n",
    "            fuzzy_match = process.extractOne(each, nomatch_b.byvar.unique(), score_cutoff=score_cutoff)\n",
    "            \n",
    "            if fuzzy_match==None:\n",
    "                fuzzy_matches.append({\"byvar\": each, \"matchvar\": np.nan, \"fuzzy_match_score\": np.nan})\n",
    "            else:\n",
    "                fuzzy_matches.append({\"byvar\": each, \"matchvar\": fuzzy_match[0], \"fuzzy_match_score\": fuzzy_match[1]})\n",
    "                \n",
    "        fuzzy_matches = pd.DataFrame(fuzzy_matches)\n",
    "        \n",
    "        ##Merge Dataframe A Nonmatches to Dataframe B Nonmatches. Append to Exact Matches and Return\n",
    "        nomatch_b.rename(columns={\"byvar\":\"matchvar\"})\n",
    "        fuzzy_merge1 = pd.merge(nomatch_a, fuzzy_matches, on=\"byvar\", how=\"left\")\n",
    "        fuzzy_merge2 = pd.merge(nomatch_a, nomatch_a, on=\"matchvar\", how=how)\n",
    "        \n",
    "        return pd.concat([matched, fuzzy_merge2], axis=0).drop([\"byvar\", \"merged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny_us_news = us_news[us_news.state==\"NY\"].copy()\n",
    "ny_ipeds = ipeds[ipeds.state==\"NY\"].copy()\n",
    "\n",
    "print ny_us_news.shape, ny_ipeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny_test = fuzzy_merge(us_news, ipeds, fuzz_on=[\"state\",\"city\",\"school\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Second Attempt :)\n",
    "\n",
    "\n",
    "##Function to Create Fuzzy Matches By-Variable Crosswalk Between List of Values A and List of Values B\n",
    "def create_crosswalk(list_a, list_b, byvar, cutoff):\n",
    "    matches = []\n",
    "    \n",
    "    for item in list_a:\n",
    "        match = process.extractOne(each, list_b, score_cutoff=cutoff)\n",
    "        \n",
    "        if fuzz_match==None:\n",
    "            matches.append({\"byvar\": each, \"matchvar\": np.nan, \"fuzzy_match_score\": np.nan})\n",
    "        else:\n",
    "            matches.append({\"byvar\": each, \"matchvar\": fuzzy_match[0], \"fuzzy_match_score\": fuzzy_match[1]})\n",
    "      \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "\n",
    "##Function to Impliment the Fuzzy Merge\n",
    "def fuzzy_merge(a, b, fuzz_on, how=\"left\", cutoffs):\n",
    "\n",
    "    ##First, Do a Regular Pandas Join & Output Matches and Nonmatches\n",
    "    a[\"in_a\"] = 1 #Set Flag for Being in DF A\n",
    "    b[\"in_b\"] = 1 #Set Flag for Being in DF B\n",
    "    \n",
    "    merged = pd.merge(a, b, how=\"outer\", on=on)\n",
    "    \n",
    "    matched = merged[(merged.in_a.notnull()) & (merged.in_b.notnull())].copy()\n",
    "    matched[\"fuzz_match_score\"] = 1.0 #score for all matched is 1.0 by default\n",
    "    \n",
    "    nomatch_a = merged[(merged.in_a.notnull()) & (merged.in_b.isnull())].copy()\n",
    "    nomatch_b = merged[(merged.in_a.isnull()) & (merged.in_b.notnull())].copy()\n",
    "    \n",
    "    ##If no nonmatches, we're done :). Return Matched Dataframe\n",
    "    if nomatch_a.shape[0]==0 or nomatch_b.shape[0]==0:\n",
    "        return matched\n",
    "    \n",
    "    ##Otherwise, Proceed to fuzzy matching. Fuzzy Merge on first by-variable, than second, etc.\n",
    "    else:\n",
    "        fuzzy_matches = pd.DataFrame() #initialize empty dataframe to hold matches\n",
    "        \n",
    "        i = 0\n",
    "        slice_a = nomatch_a.copy()\n",
    "        slice_b = nomatch_b.copy()\n",
    "        \n",
    "        while i < len(fuzz_on):\n",
    "            byvar=fuzz_on[i]\n",
    "            cutoff = cutoffs[i]\n",
    "            \n",
    "            list_a = slice_a[byvar].unique().tolist()\n",
    "            list_b = slice_a[byvar].unique().tolist()\n",
    "            \n",
    "            crosswalk = \n",
    "            \n",
    "            i+=1\n",
    "        \n",
    "        \n",
    "        ##Merge Dataframe A Nonmatches to Dataframe B Nonmatches. Append to Exact Matches and Return\n",
    "        nomatch_b.rename(columns={\"byvar\":\"matchvar\"})\n",
    "        fuzzy_merge1 = pd.merge(nomatch_a, fuzzy_matches, on=\"byvar\", how=\"left\")\n",
    "        fuzzy_merge2 = pd.merge(nomatch_a, nomatch_a, on=\"matchvar\", how=how)\n",
    "        \n",
    "        return pd.concat([matched, fuzzy_merge2], axis=0).drop([\"byvar\", \"merged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partial_fuzzy_merge(a, b, exact_on, fuzz_on, how=\"left\", cutoffs):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
